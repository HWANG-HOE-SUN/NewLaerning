# 패턴인식과 머신러닝
## 크리스토퍼 비숍(Christopher M. Bishop)
> ### Chap01

1-6 정보이론

**< 정의 >**

**정보란?** => ex)이산 확률 변수 x가 있다고 할 때 x의 값을 학습하는데 있어서 **'정보의 놀라움의 정도'**
정보량 - h(x) , 해당 사건 x에 대한 확률 분포 - p(x)라고 함.
> Ex)두 개의 연관 되지 않은 사건 x,y가 각각 일어 났다면 이로부터 얻는 정보량은 각각의 합이 될 것이다. 즉, h(x,y) = h(x) + h(y)
두 사건은 통계적으로 독립이므로 p(x,y) = p(x)p(y)인데 '정보-확률'의 관계는 로그 관계에 해당함을 알 수 있다.

h(x) = -log2p(x) ( 정보 = log(사건의 확률) , 음수의 의미? = 정보량이 마이너스가 되지 않도록 붙였음 log2의0.5 ... 이런건 음수로 나오므로)




